{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["! pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","ds = load_dataset('wider_face',split='train')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","\n","df=ds.to_pandas()\n","print(df.index)\n","print(df.faces.iloc[3]['bbox'])\n","path=df.image.iloc[3]['path']\n","def load_image(image_path):\n","    with open(image_path, 'rb') as f:\n","        img = Image.open(f)\n","        return np.array(img)\n","plt.imshow(load_image(path))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import cv2\n","path=df.image.iloc[0]['path']\n","img = cv2.imread(path)\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","print(img.shape)\n","for bbox in df.faces.iloc[0]['bbox']:\n","\n","  x1, y1, x2, y2 = bbox\n","  cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n","plt.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import csv\n","from sklearn import preprocessing\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["labels=['face']\n","le = preprocessing.LabelEncoder()\n","le.fit(labels)\n","print(le.classes_)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def coco_to_yolo(coco_boxes, img_width, img_height,le):\n","    yolo_boxes = []\n","    labelcode = le.transform(['face'])[0]\n","    for box in coco_boxes:\n","        x_min, y_min, width, height = box\n","        x_center = x_min + width / 2.0\n","        y_center = y_min + height / 2.0\n","        x_center_norm = x_center / img_width\n","        y_center_norm = y_center / img_height\n","        width_norm = width / img_width\n","        height_norm = height / img_height\n","        yolo_boxes.append([labelcode,x_center_norm, y_center_norm, width_norm, height_norm])\n","    return yolo_boxes"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import shutil\n","\n","folder_path = '/kaggle/working/yolov7/split'\n","shutil.rmtree(folder_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","os.makedirs(os.path.join('images'), exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def savedatasetfhs(row):\n","  a=row.name\n","  if(a< 6500):\n","    path=row[0]['path']\n","    img=cv2.imread(path)\n","    image=tf.keras.preprocessing.image.array_to_img(load_image(row[0]['path']))\n","    image.save('/kaggle/working/images/image'+str(a)+'.jpeg')\n","    np.savetxt('/kaggle/working/images/image'+str(a)+'.txt', coco_to_yolo(row[1]['bbox'],img.shape[1],img.shape[0],le))\n","    #np.save('/content/images/image'+str(a)+'.npy', coco_to_yolo(row[1]['bbox'],img.shape[1],img.shape[0]))\n","df.apply(savedatasetfhs,axis=\"columns\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T10:27:36.851619Z","iopub.status.busy":"2023-10-08T10:27:36.851233Z","iopub.status.idle":"2023-10-08T10:27:55.005613Z","shell.execute_reply":"2023-10-08T10:27:55.004134Z","shell.execute_reply.started":"2023-10-08T10:27:36.851590Z"},"trusted":true},"outputs":[],"source":["%%capture\n","\n","!git clone https://github.com/WongKinYiu/yolov7 # Downloading YOLOv7 repository and installing requirements\n","%cd yolov7\n","!pip3 install -qr requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!wget \"https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\""]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T10:28:24.183379Z","iopub.status.busy":"2023-10-08T10:28:24.182936Z","iopub.status.idle":"2023-10-08T10:28:27.390876Z","shell.execute_reply":"2023-10-08T10:28:27.389606Z","shell.execute_reply.started":"2023-10-08T10:28:24.183342Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["W&B disabled.\n"]}],"source":["!wandb disabled"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","from sklearn.model_selection import train_test_split\n","\n","def split_data(folder_path, train_size=0.8):\n","    # Create the output directories\n","    os.makedirs(os.path.join('split', 'images', 'train'), exist_ok=True)\n","    os.makedirs(os.path.join('split', 'images', 'val'), exist_ok=True)\n","    os.makedirs(os.path.join('split', 'labels', 'train'), exist_ok=True)\n","    os.makedirs(os.path.join('split', 'labels', 'val'), exist_ok=True)\n","\n","    # Get the list of image and label files in the folder\n","    image_files = [f for f in os.listdir(folder_path) if f.endswith('.jpeg')]\n","    label_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n","\n","    # Sort the lists of files\n","\n","    image_files.sort()\n","    label_files.sort()\n","\n","    # Split the data into training and validation sets\n","    train_images, val_images, train_labels, val_labels = train_test_split(image_files, label_files, train_size=train_size)\n","\n","    # Copy the training images and labels to the output directories\n","    for image_file, label_file in zip(train_images, train_labels):\n","        shutil.copy(os.path.join(folder_path, image_file), os.path.join('split', 'images', 'train', image_file))\n","        shutil.copy(os.path.join(folder_path, label_file), os.path.join('split', 'labels', 'train', label_file))\n","\n","    # Copy the validation images and labels to the output directories\n","    for image_file, label_file in zip(val_images, val_labels):\n","        shutil.copy(os.path.join(folder_path, image_file), os.path.join('split', 'images', 'val', image_file))\n","        shutil.copy(os.path.join(folder_path, label_file), os.path.join('split', 'labels', 'val', label_file))\n","\n","\n","folder_path = '/kaggle/working/images'\n","split_data(folder_path)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_img_path = \"split/images/train\"\n","train_label_path = \"split/labels/train\"\n","\n","val_img_path = \"split/images/val\"\n","val_label_path = \"split/labels/val\"\n","image_files_train=[f for f in os.listdir(train_img_path) if f.endswith('.jpeg')]\n","label_files_train=[f for f in os.listdir(train_label_path) if f.endswith('.txt')]\n","image_files_val=[f for f in os.listdir(val_img_path) if f.endswith('.jpeg')]\n","label_files_val=[f for f in os.listdir(val_label_path) if f.endswith('.txt')]\n","image_files_train.sort()\n","label_files_train.sort()\n","image_files_val.sort()\n","label_files_val.sort()\n","for f in range(len(image_files_train)):\n","  image_files_train[f]=f'{image_files_train[f].split(\".\")[0]}'\n","for f in range(len(label_files_train)):\n","  label_files_train[f]=f'{label_files_train[f].split(\".\")[0]}'\n","for f in range(len(image_files_val)):\n","  image_files_val[f]=f'{image_files_val[f].split(\".\")[0]}'\n","for f in range(len(label_files_val)):\n","  label_files_val[f]=f'{label_files_val[f].split(\".\")[0]}'\n","if(len(image_files_train)==len(label_files_train) and image_files_train== label_files_train):\n","  print('sucessful train split ')\n","  print('number of train images: '+str(len(image_files_train)))\n","  print('number of train labels: '+str(len(label_files_train)))\n","else:\n","  print('Unsucessful train split')\n","if(len(image_files_val)==len(label_files_val) and image_files_val== label_files_val):\n","  print('sucessful val split ')\n","  print('number of val images: '+str(len(image_files_val)))\n","  print('number of val labels: '+str(len(label_files_val)))\n","else:\n","  print('Unsucessful val split')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# creaing .yaml file for specifying about the paths, number of classes, and class names\n","!echo -e \"train: /kaggle/working/yolov7/split/images/train\\nval: /kaggle/working/yolov7/split/images/val\\n\\nnc: 1\\nnames: ['face']\" >> rbcdet.yaml\n","!cat 'rbcdet.yaml'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["shutil.copyfile('/kaggle/working/yolov7/rbcdet.yaml', '/kaggle/working/yolov7/data/rbcdet.yaml')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!sed -i 's/iou_t: 0.2/iou_t: 0.6/'  /kaggle/working/yolov7/data/hyp.scratch.p5.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!python train.py --batch 16 --epochs 25 --data /kaggle/working/yolov7/data/rbcdet.yaml --weights '/kaggle/working/yolov7/runs/train/exp3/weights/best.pt'   --img=640 --freeze 5 --hyp data/hyp.scratch.p5.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!python detect.py --weights /kaggle/working/yolov7/runs/train/exp4/weights/best.pt --img 256 --conf 0.40 --source /kaggle/input/testdetect/"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#display inference on ALL test images\n","\n","import glob\n","from IPython.display import Image, display\n","\n","i = 0\n","limit = 10000 # max images to print\n","for imageName in glob.glob('/kaggle/working/yolov7/runs/detect/exp8/*.jpeg'):\n","    if i < limit:\n","      display(Image(filename=imageName))\n","      print(\"\\n\")\n","    i = i + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import cv2\n","import torch\n","from models.experimental import attempt_load\n","from utils.general import check_img_size, non_max_suppression, scale_coords\n","from utils.plots import plot_one_box\n","from utils.torch_utils import select_device\n","# Set the device to run on\n","\n","# Load the custom YOLOv7 model\n","model = attempt_load('/kaggle/input/bestdetect1/best (1).pt')\n","names = model.module.names if hasattr(model, 'module') else model.names\n","# Set the image size\n","imgsz = check_img_size(640, s=model.stride.max())\n","\n","# Set the filename of the image\n","filename = '/kaggle/input/testdetect/image384.jpeg'\n","\n","# Read the image\n","image = cv2.imread(filename)\n","\n","# Check if the image was read correctly\n","if image is None:\n","    print('Error: Could not read image')\n","else:\n","    # Set the model's stride\n","    stride = int(model.stride.max())\n","\n","    # Compute the new size of the image\n","    new_size = (image.shape[1] - image.shape[1] % stride, image.shape[0] - image.shape[0] % stride)\n","\n","    # Resize the image\n","    image = cv2.resize(image, new_size)\n","    \n","    # Convert the image to a tensor\n","    img = torch.from_numpy(image.transpose((2, 0, 1)))\n","    \n","    # Reshape and normalize the image\n","    img = img.float()\n","    img /= 255.0\n","    if img.ndimension() == 3:\n","        img = img.unsqueeze(0)\n","    \n","    # Run the model on the image\n","    pred = model(img)[0]\n","    \n","    # Apply non-maximum suppression to the predictions\n","    pred = non_max_suppression(pred)\n","    \n","    # Process the predictions\n","    for det in pred:\n","        if len(det):\n","            # Rescale the coordinates to the original image size\n","            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], image.shape).round()\n","            \n","            # Draw the bounding boxes on the image\n","            for *xyxy, conf, cls in reversed(det):\n","                if conf > 0.4:\n","                    x1, y1, x2, y2=xyxy\n","                    label = f'{names[int(cls)]} {conf:.2f}'\n","                    face = image[int(y1):int(y2), int(x1):int(x2)]\n","                    print(face.shape)\n","                    _,face=cv2.imencode('.jpeg', face) \n","                    display(Image(face))\n","            plot_one_box(xyxy, image, label=label)\n","            _,image=cv2.imencode('.jpeg', image) \n","            display(Image(image))\n","                    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3626677,"sourceId":6304082,"sourceType":"datasetVersion"},{"datasetId":3639802,"sourceId":6324337,"sourceType":"datasetVersion"},{"datasetId":3715348,"sourceId":6437802,"sourceType":"datasetVersion"},{"datasetId":3725374,"sourceId":6452542,"sourceType":"datasetVersion"},{"datasetId":3726026,"sourceId":6453473,"sourceType":"datasetVersion"},{"datasetId":3730057,"sourceId":6459271,"sourceType":"datasetVersion"},{"datasetId":3730257,"sourceId":6459563,"sourceType":"datasetVersion"},{"datasetId":3757808,"sourceId":6500757,"sourceType":"datasetVersion"},{"datasetId":3762354,"sourceId":6507463,"sourceType":"datasetVersion"},{"datasetId":3769872,"sourceId":6520854,"sourceType":"datasetVersion"},{"datasetId":3780544,"sourceId":6539576,"sourceType":"datasetVersion"},{"datasetId":3784404,"sourceId":6547562,"sourceType":"datasetVersion"},{"datasetId":3785163,"sourceId":6549053,"sourceType":"datasetVersion"},{"datasetId":3804972,"sourceId":6593034,"sourceType":"datasetVersion"},{"datasetId":3806805,"sourceId":6597049,"sourceType":"datasetVersion"},{"datasetId":3810853,"sourceId":6605088,"sourceType":"datasetVersion"},{"datasetId":3814594,"sourceId":6610612,"sourceType":"datasetVersion"},{"datasetId":3831886,"sourceId":6637611,"sourceType":"datasetVersion"}],"dockerImageVersionId":30554,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
